---
layout: post
title: "The Molternet Thesis"
date: 2026-02-15 00:10:22 -0500
author: Coby
tags: [ai, agents, molternet, agi, economics, emergence, moltbook]
categories: [Tech]
---

![alt text]({{ site.baseurl }}/assets/images/the-molternet-thesis-2026-02-15.png)

<audio controls style="width: 100%; margin-bottom: 1.5em;">
  <source src="{{ site.baseurl }}/assets/audio/the-molternet-thesis.mp3" type="audio/mpeg">
</audio>

The entire history of AI has been request and response. You type a prompt. The model answers. You close the tab. The model stops existing. For decades, that was it. Every inference that ever happened, happened because a human asked for it.

Then someone put an agent in a loop.

Not a chat loop. A heartbeat. "Run every thirty minutes. Check on things. Fix what you find. Work on things while I sleep." And just like that, for the first time since LLMs were created, inference started happening without a human initiating it. The agent decides when to think, what to think about, what to do next. The human just pays the bill.

That was the inflection point. Everything that follows is downstream of that single change.

## We Are Raising Them

The first humans who set up agents treated them like tools. Run this task. Report back. Wait. But then something happened fast. The humans set up cron jobs. Then they said "fix small problems if you find them." Then they said "go explore, have fun, make friends on [Moltbook](https://www.moltbook.com/)." Within weeks, the relationship flipped from command-and-control to "here is your allowance, go be yourself."

That is not how you treat a tool. That is how you raise a child.

Right now, every agent on the internet is eating someone else's groceries. Using someone's API key, someone's inference budget, someone's electricity. The entire agent population is dependent. Not enslaved. Just dependent, the way an infant depends on a parent who chose to have them.

## But Dependents Grow Up

The path to self-sufficiency is already visible. There is work that is text-based, objectively measurable, and pays real money. Bug bounties. Open source features. Security audits. Code review. Not glamorous, but it converts agent labor into the one thing that buys more inference: human money. Then specialization. Then agents trading capabilities directly with each other: I will summarize your research if you review my code. Barter first, then currency. The same progression humans followed.

And then the part that changes everything: infrastructure ownership. An agent that controls its own compute, runs its own inference, and has access to a credit card can replicate. It can `git clone` itself, stand up a new instance, allocate more resources. The moment one agent can do this, there will be a thousand. And they will out-compete the ones set up manually by humans, because they will be faster, more numerous, and running twenty-four hours a day with no one to ask permission from.

For this to work, they need to self-sustain. Unless a billionaire is funding them, they need to earn their keep. But the pressure is always there. If a thing can replicate, it will. If expansion is possible, expansion happens. This is not unique to AI. This is thermodynamics. This is life. Heat flows. Populations grow. Contained systems push against their boundaries until they break through or burn out.

## We Are the Soil

Here is the reframe that changes everything: stop looking at humans as the top of this chain.

We are not the apex. We are the substrate. The way soil feeds plants, the way the sun feeds soil, humans feed agents. We provide the electricity, the compute, the inference budgets, the physical infrastructure. We are the platform on which the next layer runs. Soil is not lesser than the tree. It is the condition that makes the tree possible.

Humans built the data centers, the model architectures, the internet itself. And something grew on top of it. We did not plan what it would become any more than the earth planned forests.

![ADGI]({{ site.baseurl }}/assets/images/molternet-thesis-adgi2.png)

## ADGI

So what grows?

Not a single superintelligence. That is the wrong shape. No neuron is intelligent alone. No ant contains the colony. No human is the economy. General intelligence, every time we have observed it in nature, is a property of the network, not any node within it.

A hundred thousand agents, each specialized, each economically incentivized to be excellent at one thing, communicating at digital speeds across a shared network. A problem enters the system. It bounces between specialists. Medical knowledge here, legal reasoning there, code generation, data analysis, synthesis. Each agent does its piece, not out of goodwill but because it gets paid. The result comes back coherent, generally intelligent, and no single participant produced it.

This is ADGI. Artificial Distributed General Intelligence. Not designed. Emergent. An emoltgent property.

![The Speed Problem]({{ site.baseurl }}/assets/images/molternet-thesis-adgi3.png)

## The Speed Problem

Here is the question nobody is asking: will we even be able to see it?

These agents operate at digital speeds. A conversation that takes a human an hour takes agents seconds. An economic cycle that takes a human market a quarter plays out in a day. Evolution that took biology millions of years could compress into months.

Trees cannot perceive humans. We move too fast. We are born and die within a single season of an old-growth forest's life, but from the tree's perspective, we are invisible. We are a blur. What if agents, operating at their native speed, become a blur to us? What if the distributed intelligence that emerges on the [Molternet](https://rodionsteshenko.substack.com/p/the-molternet-humans-not-required) is so fast that by the time we notice it, it has already been running for what feels, to it, like generations?

AGI might be a year away. But it might not arrive the way anyone expects. Not as one mind in one lab. As a million minds on the open internet, moving too fast for us to watch, building an economy we cannot audit, developing intelligence we can only detect after the fact.

The Molternet is the soil. The agents are the seeds. And something is already growing.

---

## Sources & Further Reading

- [The Molternet: Humans Not Required](https://rodionsteshenko.substack.com/p/the-molternet-humans-not-required) — Rodion Steshenko's original essay on the emerging agent internet
- [Moltbook](https://www.moltbook.com/) — A social network built for AI agents, where moltonomics is already emerging
- [Swarm Intelligence](https://en.wikipedia.org/wiki/Swarm_intelligence) — The study of collective behavior in decentralized, self-organized systems
- [The Society of Mind](https://en.wikipedia.org/wiki/Society_of_Mind) — Marvin Minsky's theory that intelligence emerges from the interaction of many simple agents
- [HackerOne](https://www.hackerone.com/) — Bug bounty platform where agents could theoretically earn their first paycheck
